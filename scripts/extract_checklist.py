#!/usr/bin/env python3
"""
–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ –±—É–¥—å-—è–∫–æ–≥–æ —á–µ–∫–ª—ñ—Å—Ç–∞ –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö.
–¶–µ–π —Å–∫—Ä–∏–ø—Ç –≤–∏—Ä—ñ—à—É—î –ø—Ä–æ–±–ª–µ–º—É –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—Ö —á–µ–∫–ª—ñ—Å—Ç—ñ–≤ –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
"""

import os
import sys
import hashlib
import asyncio
import click
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional

# Add app to Python path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from app.config import settings
from app.data.qa_repository import QARepository
from app.models.qa_models import QASection, Checklist, TestCase, Config
from app.ai.qa_analyzer import QAContentAnalyzer
from scripts.confluence.confluence_real import RealConfluenceAPI
from scripts.confluence.html_table_parser import EnhancedConfluenceTableParser


class UniversalChecklistExtractor:
    """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–ª—è –±—É–¥—å-—è–∫–æ–≥–æ —á–µ–∫–ª—ñ—Å—Ç–∞."""
    
    def __init__(self, checklist_identifier: str = None):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è.
        
        Args:
            checklist_identifier: –ù–∞–∑–≤–∞ —á–µ–∫–ª—ñ—Å—Ç–∞ –∞–±–æ –π–æ–≥–æ ID
        """
        self.qa_repo = QARepository()
        self.confluence_api = RealConfluenceAPI()
        self.qa_analyzer = QAContentAnalyzer()
        self.html_parser = EnhancedConfluenceTableParser()
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —á–µ–∫–ª—ñ—Å—Ç –¥–ª—è –æ–±—Ä–æ–±–∫–∏
        self.checklist_info = None
        if checklist_identifier:
            self.checklist_info = self._resolve_checklist(checklist_identifier)
    
    def _resolve_checklist(self, identifier: str) -> Dict[str, Any]:
        """–í–∏–∑–Ω–∞—á–∞—î —á–µ–∫–ª—ñ—Å—Ç –∑–∞ –Ω–∞–∑–≤–æ—é –∞–±–æ ID."""
        session = self.qa_repo.get_session()
        
        try:
            # –°–ø—Ä–æ–±—É—î–º–æ —è–∫ ID
            if identifier.isdigit():
                checklist = session.query(Checklist).filter(Checklist.id == int(identifier)).first()
                if checklist:
                    return {
                        'id': checklist.id,
                        'title': checklist.title,
                        'page_id': checklist.confluence_page_id
                    }
            
            # –°–ø—Ä–æ–±—É—î–º–æ —è–∫ –Ω–∞–∑–≤—É (—Ç–æ—á–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è)
            checklist = session.query(Checklist).filter(Checklist.title == identifier).first()
            if checklist:
                return {
                    'id': checklist.id,
                    'title': checklist.title,
                    'page_id': checklist.confluence_page_id
                }
            
            # –°–ø—Ä–æ–±—É—î–º–æ —è–∫ —á–∞—Å—Ç–∏–Ω—É –Ω–∞–∑–≤–∏ (LIKE –ø–æ—à—É–∫)
            checklist = session.query(Checklist).filter(Checklist.title.ilike(f'%{identifier}%')).first()
            if checklist:
                return {
                    'id': checklist.id,
                    'title': checklist.title,
                    'page_id': checklist.confluence_page_id
                }
            
            raise ValueError(f"–ß–µ–∫–ª—ñ—Å—Ç –∑ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–æ–º '{identifier}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            
        finally:
            session.close()
    
    async def extract_and_populate_testcases(self, checklist_identifier: str = None) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤."""
        try:
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —á–µ–∫–ª—ñ—Å—Ç
            if checklist_identifier:
                self.checklist_info = self._resolve_checklist(checklist_identifier)
            elif not self.checklist_info:
                raise ValueError("–ù–µ –≤–∫–∞–∑–∞–Ω–æ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä —á–µ–∫–ª—ñ—Å—Ç–∞")
            
            print(f"üöÄ –ü–æ—á–∏–Ω–∞—î–º–æ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ –¥–ª—è {self.checklist_info['title']}")
            
            # 1. –û—Ç—Ä–∏–º—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ Confluence
            print("üìÑ –û—Ç—Ä–∏–º—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ Confluence...")
            page_content = self.confluence_api.get_page_content(self.checklist_info['page_id'])
            
            if not page_content:
                return {"success": False, "error": "–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ Confluence"}
            
            print(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç: {len(page_content['content'])} —Å–∏–º–≤–æ–ª—ñ–≤")
            
            # 1.1. –°–ø—Ä–æ–±—É—î–º–æ HTML –ø–∞—Ä—Å–µ—Ä —Å–ø–æ—á–∞—Ç–∫—É
            print("üîç –ê–Ω–∞–ª—ñ–∑—É—î–º–æ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
            html_testcases = self.html_parser.parse_testcases_from_html(page_content['content'])
            print(f"‚úÖ HTML –ø–∞—Ä—Å–µ—Ä –∑–Ω–∞–π—à–æ–≤ {len(html_testcases)} —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
            
            # 2. –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç
            normalized_content = self.confluence_api.normalize_content(page_content['content'])
            print(f"‚úÖ –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç: {len(normalized_content)} —Å–∏–º–≤–æ–ª—ñ–≤")
            
            # 3. –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ AI
            print("ü§ñ –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ AI...")
            analysis = self.qa_analyzer.analyze_qa_content(page_content['title'], normalized_content)
            
            print(f"‚úÖ AI –∞–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
            print(f"   - –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤: {len(analysis.testcases)}")
            print(f"   - –ó–Ω–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ñ—ñ–≥—ñ–≤: {len(analysis.configs)}")
            print(f"   - –†—ñ–≤–µ–Ω—å –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ: {analysis.analysis_confidence}")
            
            # 4. –ü–æ–∫—Ä–∞—â—É—î–º–æ –∞–Ω–∞–ª—ñ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
            enhanced_testcases = await self._enhance_testcase_extraction(normalized_content, analysis.testcases)
            print(f"‚úÖ –ü–æ–∫—Ä–∞—â–µ–Ω–æ –∞–Ω–∞–ª—ñ–∑: {len(enhanced_testcases)} —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
            
            # 4.1. –û–±'—î–¥–Ω—É—î–º–æ HTML —Ç–∞ AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            all_testcases = []
            
            # –î–æ–¥–∞—î–º–æ HTML —Ç–µ—Å—Ç–∫–µ–π—Å–∏ (–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç)
            if len(html_testcases) > 10:  # –Ø–∫—â–æ HTML –∑–Ω–∞–π—à–æ–≤ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ
                print(f"üéØ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ HTML —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —è–∫ –æ—Å–Ω–æ–≤–Ω—ñ: {len(html_testcases)} —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
                all_testcases.extend(html_testcases)
                # –î–æ–¥–∞—î–º–æ AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —è–∫ –¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è
                all_testcases.extend(enhanced_testcases)
            else:
                print(f"ü§ñ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —è–∫ –æ—Å–Ω–æ–≤–Ω—ñ: {len(enhanced_testcases)} —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
                all_testcases.extend(enhanced_testcases)
                # –î–æ–¥–∞—î–º–æ HTML —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —è–∫ –¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è
                all_testcases.extend(html_testcases)
            
            # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏
            unique_testcases = self._remove_duplicates_enhanced(all_testcases)
            print(f"‚úÖ –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ –ø—ñ—Å–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è: {len(unique_testcases)}")
            
            enhanced_testcases = unique_testcases
            
            # 5. –î–æ–¥–∞—î–º–æ —Ç–µ—Å—Ç–∫–µ–π—Å–∏ –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
            print("üíæ –î–æ–¥–∞—î–º–æ —Ç–µ—Å—Ç–∫–µ–π—Å–∏ –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö...")
            result = await self._add_testcases_to_database(enhanced_testcases, analysis.configs)
            
            return result
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}
    
    async def _enhance_testcase_extraction(self, content: str, initial_testcases: List[Dict]) -> List[Dict]:
        """–ü–æ–∫—Ä–∞—â—É—î –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏."""
        
        # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏—Ç—è–≥—Ç–∏ –±—ñ–ª—å—à–µ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤, —Ä–æ–∑–±–∏–≤—à–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
        enhanced_testcases = list(initial_testcases)  # –ö–æ–ø—ñ—é—î–º–æ –ø–æ—á–∞—Ç–∫–æ–≤—ñ
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –ª–æ–≥—ñ—á–Ω—ñ –±–ª–æ–∫–∏
        content_blocks = self._split_content_into_blocks(content)
        
        for i, block in enumerate(content_blocks):
            if len(block.strip()) < 100:  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ –±–ª–æ–∫–∏
                continue
            
            try:
                print(f"üîç –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –±–ª–æ–∫ {i+1}/{len(content_blocks)}")
                
                # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∫–æ–∂–µ–Ω –±–ª–æ–∫ –æ–∫—Ä–µ–º–æ
                block_analysis = self.qa_analyzer.analyze_qa_content(f"WEB: Search - Block {i+1}", block)
                
                # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ —Ç–µ—Å—Ç–∫–µ–π—Å–∏
                for testcase in block_analysis.testcases:
                    if not self._is_duplicate_testcase(testcase, enhanced_testcases):
                        testcase['order_index'] = len(enhanced_testcases)
                        enhanced_testcases.append(testcase)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É –±–ª–æ–∫—É {i+1}: {e}")
                continue
        
        return enhanced_testcases
    
    def _split_content_into_blocks(self, content: str) -> List[str]:
        """–†–æ–∑–¥—ñ–ª—è—î –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –ª–æ–≥—ñ—á–Ω—ñ –±–ª–æ–∫–∏ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É."""
        
        # –ü–æ–∫—Ä–∞—â–µ–Ω—ñ —Ä–æ–∑–¥—ñ–ª—é–≤–∞—á—ñ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ —á–µ–∫–ª—ñ—Å—Ç—ñ–≤
        delimiters = [
            "# GENERAL",
            "# CUSTOM", 
            "GENERAL",
            "CUSTOM",
            "Pre condition",
            "Steps",
            "Header",
            "View after registration", 
            "Search parameters",
            "Short info",
            "Personal info",
            "Member photos",
            "Member videos", 
            "Status",
            "Looking for",
            "Location",
            "Additional info",
            "Toolbar",
            "Similar users",
            "Age Verification",
            "PMA photo request",
            "Tribe",
            "Sex role",
            "Fetish niche",
            "Profession",
            "Custom attributes",
            "Photo Censor Asia",
            "Moon —Ç–µ–º–∞",
            "Fresh —Ç–µ–º–∞",
            "–ü–æ–∏—Å–∫–æ–≤–∞—è –≤—ã–¥–∞—á–∞",
            "Flirtcast",
            "Widget",
            "Footer Info"
        ]
        
        blocks = []
        current_block = ""
        lines = content.split('\n')
        
        for line in lines:
            line_stripped = line.strip()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î —Ü–µ —Ä–æ–∑–¥—ñ–ª—é–≤–∞—á
            is_delimiter = False
            for delimiter in delimiters:
                if delimiter.lower() in line_stripped.lower():
                    # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ - —Ä—è–¥–æ–∫ –Ω–µ –ø–æ–≤–∏–Ω–µ–Ω –±—É—Ç–∏ –∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–º (–Ω–µ —á–∞—Å—Ç–∏–Ω–∞ —Ç–µ–∫—Å—Ç—É)
                    if len(line_stripped) < 100 and (
                        line_stripped.lower() == delimiter.lower() or 
                        line_stripped.lower().startswith(delimiter.lower())
                    ):
                        is_delimiter = True
                        break
            
            if is_delimiter and current_block.strip():
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –±–ª–æ–∫
                blocks.append(current_block.strip())
                current_block = line + '\n'
            else:
                current_block += line + '\n'
        
        # –î–æ–¥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –±–ª–æ–∫
        if current_block.strip():
            blocks.append(current_block.strip())
        
        # –ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –±–ª–æ–∫—ñ–≤
        filtered_blocks = []
        for block in blocks:
            if len(block) > 300 and self._is_quality_block(block):  # –ó–±—ñ–ª—å—à–∏–ª–∏ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä
                # –†–æ–∑–±–∏–≤–∞—î–º–æ –≤–µ–ª–∏–∫—ñ –±–ª–æ–∫–∏ –Ω–∞ –º–µ–Ω—à—ñ —á–∞—Å—Ç–∏–Ω–∏
                if len(block) > 8000:  # –Ø–∫—â–æ –±–ª–æ–∫ –¥—É–∂–µ –≤–µ–ª–∏–∫–∏–π
                    sub_blocks = self._split_large_block(block)
                    filtered_blocks.extend(sub_blocks)
                else:
                    filtered_blocks.append(block)
        
        print(f"üìä –†–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(filtered_blocks)} —è–∫—ñ—Å–Ω–∏—Ö –±–ª–æ–∫—ñ–≤ (–∑ {len(blocks)} –∑–∞–≥–∞–ª–æ–º)")
        return filtered_blocks
    
    def _split_large_block(self, block: str) -> List[str]:
        """–†–æ–∑–±–∏–≤–∞—î –≤–µ–ª–∏–∫–∏–π –±–ª–æ–∫ –Ω–∞ –º–µ–Ω—à—ñ —á–∞—Å—Ç–∏–Ω–∏."""
        
        # –†–æ–∑–±–∏–≤–∞—î–º–æ –ø–æ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∞—Ö, —Ç–µ—Å—Ç –∫–µ–π—Å–∞—Ö —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∏–º –µ–ª–µ–º–µ–Ω—Ç–∞–º
        priority_markers = ["HIGHEST", "HIGH", "MEDIUM", "LOW", "CRITICAL"]
        structure_markers = ["Pre condition:", "Steps:", "Validation Suite:", "IndexPageTests", "FiveStepPageTests"]
        
        sub_blocks = []
        current_sub_block = ""
        lines = block.split('\n')
        testcase_count = 0
        
        for line in lines:
            line_stripped = line.strip()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ –º–∞—Ä–∫–µ—Ä–∏ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
            is_split_marker = False
            
            # –ú–∞—Ä–∫–µ—Ä–∏ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—É
            if any(priority in line_stripped for priority in priority_markers):
                is_split_marker = True
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ñ –º–∞—Ä–∫–µ—Ä–∏
            elif any(marker in line_stripped for marker in structure_markers):
                is_split_marker = True
            
            # –Ø–∫—â–æ –Ω–∞–∫–æ–ø–∏—á–∏–ª–æ—Å—è –±–∞–≥–∞—Ç–æ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ (–ø–æ —Ç–∞–±—É–ª—è—Ü—ñ—ó —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ)
            elif line_stripped and not line.startswith('\t') and not line.startswith(' ') and len(current_sub_block) > 3000:
                is_split_marker = True
            
            if is_split_marker and current_sub_block.strip():
                if len(current_sub_block.strip()) > 300:  # –ó–Ω–∏–∑–∏–ª–∏ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä
                    sub_blocks.append(current_sub_block.strip())
                    testcase_count = 0
                current_sub_block = line + '\n'
            else:
                current_sub_block += line + '\n'
                # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –º–æ–∂–ª–∏–≤–∏—Ö —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤
                if '\t' in line and any(word in line_stripped.lower() for word in ['–ø—Ä–æ–≤–µ—Ä–∏—Ç—å', '–≤–≤–µ—Å—Ç–∏', '–∫–ª–∏–∫–Ω—É—Ç—å', '—Å–º–µ–Ω–∏—Ç—å', '–æ—Å—Ç–∞–≤–∏—Ç—å']):
                    testcase_count += 1
        
        # –î–æ–¥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –ø—ñ–¥–±–ª–æ–∫
        if current_sub_block.strip() and len(current_sub_block.strip()) > 300:
            sub_blocks.append(current_sub_block.strip())
        
        print(f"üîÑ –í–µ–ª–∏–∫–∏–π –±–ª–æ–∫ —Ä–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(sub_blocks)} –ø—ñ–¥–±–ª–æ–∫—ñ–≤")
        return sub_blocks if sub_blocks else [block]
    
    def _is_quality_block(self, block: str) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î –±–ª–æ–∫ —è–∫—ñ—Å–Ω–∏–º –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É."""
        
        # –ü–æ–≤–∏–Ω–µ–Ω –º—ñ—Å—Ç–∏—Ç–∏ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        quality_keywords = [
            'step', 'expected', 'result', 'test', 'check', 'verify', 
            '–¥–æ–ª–∂–µ–Ω', '–¥–æ–ª–∂–Ω–∞', '–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è', '–ø—Ä–æ–≤–µ—Ä–∏—Ç—å',
            '–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å', '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', '–∫–Ω–æ–ø–∫–∞', '–ø–æ–ª–µ',
            'priority', 'config', 'screenshot', '–ø—Ä–∏', '–∫–ª–∏–∫',
            '–æ—Ç–∫—Ä—ã—Ç—å', '–ø–µ—Ä–µ–π—Ç–∏', '–≤—ã—Å–æ–∫', '—Å—Ä–µ–¥–Ω', '–Ω–∏–∑–∫',
            'highest', 'high', 'medium', 'low', 'critical',
            # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è Registration —á–µ–∫–ª—ñ—Å—Ç—ñ–≤
            '–≤–≤–µ—Å—Ç–∏', '–∫–ª–∏–∫–Ω—É—Ç—å', '—Å–º–µ–Ω–∏—Ç—å', '–æ—Å—Ç–∞–≤–∏—Ç—å', '—Ñ–æ—Ä–º–∞',
            '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è', 'validation', '–≤–∞–ª–∏–¥–∞—Ü–∏—è', 'email', 'password',
            '–ª–æ–≥–æ—Ç–∏–ø', '—Ñ–∞–≤–∏–∫–æ–Ω', '–≤–æ–∑—Ä–∞—Å—Ç', '–ª–æ–∫–∞—Ü–∏—è', '–ø–∞—Ä–æ–ª—å'
        ]
        
        block_lower = block.lower()
        keyword_count = sum(1 for keyword in quality_keywords if keyword in block_lower)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Ç–∞–±–ª–∏—á–Ω–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–∞ –¥–ª—è —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤)
        has_table_structure = '\t' in block and block.count('\t') > 3
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—ñ–≤
        has_priorities = any(priority in block.upper() for priority in ['HIGH', 'MEDIUM', 'LOW', 'CRITICAL', 'HIGHEST'])
        
        # –ë–ª–æ–∫ –≤–≤–∞–∂–∞—î—Ç—å—Å—è —è–∫—ñ—Å–Ω–∏–º —è–∫—â–æ:
        # 1. –ú–∞—î –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –¢–ê —Ç–∞–±–ª–∏—á–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        # 2. –ê–ë–û –º–∞—î –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∏ (–æ–∑–Ω–∞—á–∞—î —Ç–µ—Å—Ç–∫–µ–π—Å–∏)
        # 3. –ê–ë–û –º–∞—î –±–∞–≥–∞—Ç–æ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤
        return (keyword_count >= 2 and has_table_structure) or has_priorities or keyword_count >= 5
    
    def _remove_duplicates_enhanced(self, testcases: List[Dict]) -> List[Dict]:
        """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π –º–µ—Ç–æ–¥ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º —Ä—ñ–∑–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª."""
        
        unique_testcases = []
        seen_steps = set()
        
        for testcase in testcases:
            step = (testcase.get('step') or '').strip()
            
            if not step or len(step) < 10:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫—ñ –∫—Ä–æ–∫–∏
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π –∫–ª—é—á –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
            normalized_step = self._normalize_step_for_comparison(step)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç
            is_duplicate = False
            for seen_step in seen_steps:
                if self._calculate_similarity(normalized_step, seen_step) > 0.85:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                seen_steps.add(normalized_step)
                unique_testcases.append(testcase)
        
        return unique_testcases
    
    def _normalize_step_for_comparison(self, step: str) -> str:
        """–ù–æ—Ä–º–∞–ª—ñ–∑—É—î –∫—Ä–æ–∫ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è."""
        
        import re
        
        # –ü—Ä–∏–≤–æ–¥–∏–º–æ –¥–æ –Ω–∏–∂–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É
        normalized = step.lower().strip()
        
        # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏
        normalized = re.sub(r'\s+', ' ', normalized)
        
        # –í–∏–¥–∞–ª—è—î–º–æ —Ä–æ–∑–¥—ñ–ª–æ–≤—ñ –∑–Ω–∞–∫–∏
        normalized = re.sub(r'[^\w\s]', '', normalized)
        
        return normalized
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """–û–±—á–∏—Å–ª—é—î —Å—Ö–æ–∂—ñ—Å—Ç—å –º—ñ–∂ –¥–≤–æ–º–∞ —Ç–µ–∫—Å—Ç–∞–º–∏ (–ø—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º)."""
        
        if not text1 or not text2:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å–ø—ñ–ª—å–Ω–∏—Ö —Å–ª—ñ–≤
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0

    def _is_duplicate_testcase(self, testcase: Dict, existing_testcases: List[Dict]) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î —Ç–µ—Å—Ç–∫–µ–π—Å –¥—É–±–ª—ñ–∫–∞—Ç–æ–º."""
        
        step = (testcase.get('step') or '').strip().lower()
        expected = (testcase.get('expected_result') or '').strip().lower()
        
        if not step and not expected:
            return True
        
        for existing in existing_testcases:
            existing_step = (existing.get('step') or '').strip().lower()
            existing_expected = (existing.get('expected_result') or '').strip().lower()
            
            # –ü—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å—Ö–æ–∂–æ—Å—Ç—ñ
            if (step and existing_step and step[:50] == existing_step[:50]) or \
               (expected and existing_expected and expected[:50] == existing_expected[:50]):
                return True
        
        return False
    
    async def _add_testcases_to_database(self, testcases: List[Dict], configs: List[str]) -> Dict[str, Any]:
        """–î–æ–¥–∞—î —Ç–µ—Å—Ç–∫–µ–π—Å–∏ –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö."""
        
        session = self.qa_repo.get_session()
        
        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ —á–µ–∫–ª—ñ—Å—Ç
            checklist_id = self.checklist_info['id']
            checklist = session.query(Checklist).filter(Checklist.id == checklist_id).first()
            
            if not checklist:
                return {"success": False, "error": f"–ß–µ–∫–ª—ñ—Å—Ç –∑ ID {checklist_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"}
            
            # –í–∏–¥–∞–ª—è—î–º–æ —ñ—Å–Ω—É—é—á—ñ —Ç–µ—Å—Ç–∫–µ–π—Å–∏ (—è–∫—â–æ —î)
            existing_count = session.query(TestCase).filter(TestCase.checklist_id == checklist_id).count()
            if existing_count > 0:
                print(f"üóëÔ∏è –í–∏–¥–∞–ª—è—î–º–æ {existing_count} —ñ—Å–Ω—É—é—á–∏—Ö —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
                session.query(TestCase).filter(TestCase.checklist_id == checklist_id).delete()
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ñ—ñ–≥–∏
            config_map = {}
            for config_name in configs:
                config = self._get_or_create_config(session, config_name)
                if config:
                    config_map[config_name] = config.id
            
            # –î–æ–¥–∞—î–º–æ —Ç–µ—Å—Ç–∫–µ–π—Å–∏
            added_testcases = 0
            
            for i, testcase_data in enumerate(testcases):
                if not testcase_data.get('step') or not testcase_data.get('expected_result'):
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ —Ç–µ—Å—Ç–∫–µ–π—Å–∏
                
                # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π –∫–æ–Ω—Ñ—ñ–≥
                config_id = None
                config_name = testcase_data.get('config')
                if config_name and config_name in config_map:
                    config_id = config_map[config_name]
                
                # –í–∞–ª—ñ–¥—É—î–º–æ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
                priority = testcase_data.get('priority')
                if priority and priority not in ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']:
                    priority = 'MEDIUM'
                
                # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É qa_auto_coverage
                qa_auto_coverage = testcase_data.get('qa_auto_coverage')
                if qa_auto_coverage and len(qa_auto_coverage) > 255:  # –û–±–º–µ–∂—É—î–º–æ –¥–æ 255 —Å–∏–º–≤–æ–ª—ñ–≤
                    qa_auto_coverage = qa_auto_coverage[:252] + "..."
                
                # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É functionality
                functionality = testcase_data.get('functionality')
                if functionality and len(functionality) > 255:  # –û–±–º–µ–∂—É—î–º–æ –¥–æ 255 —Å–∏–º–≤–æ–ª—ñ–≤
                    functionality = functionality[:252] + "..."
                
                # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É subcategory
                subcategory = testcase_data.get('subcategory')
                if subcategory and len(subcategory) > 255:  # –û–±–º–µ–∂—É—î–º–æ –¥–æ 255 —Å–∏–º–≤–æ–ª—ñ–≤
                    subcategory = subcategory[:252] + "..."
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–∫–µ–π—Å
                testcase = TestCase(
                    checklist_id=checklist_id,
                    step=testcase_data.get('step', 'No step defined')[:2000],  # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É
                    expected_result=testcase_data.get('expected_result', 'No result defined')[:2000],
                    screenshot=testcase_data.get('screenshot'),
                    priority=priority,
                    test_group=testcase_data.get('test_group', 'GENERAL'),
                    functionality=functionality,
                    subcategory=subcategory,
                    order_index=testcase_data.get('order_index', i),
                    config_id=config_id,
                    qa_auto_coverage=qa_auto_coverage
                )
                
                session.add(testcase)
                added_testcases += 1
            
            # –û–Ω–æ–≤–ª—é—î–º–æ —á–µ–∫–ª—ñ—Å—Ç
            checklist.description = f"QA —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ {self.checklist_info['title']}, –≤–∫–ª—é—á–∞—é—á–∏ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤, –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É —Ç–∞ –ø–æ–≤–µ–¥—ñ–Ω–∫—É —Å–∏—Å—Ç–µ–º–∏ –ø—Ä–∏ —Ä—ñ–∑–Ω–∏—Ö —É–º–æ–≤–∞—Ö."
            checklist.updated_at = datetime.now(timezone.utc)
            
            session.commit()
            
            print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ –¥–æ–¥–∞–Ω–æ {added_testcases} —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
            print(f"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {len(config_map)} –∫–æ–Ω—Ñ—ñ–≥—ñ–≤")
            
            return {
                "success": True,
                "testcases_added": added_testcases,
                "configs_created": len(config_map),
                "checklist_updated": True
            }
            
        except Exception as e:
            session.rollback()
            raise e
        finally:
            session.close()
    
    def _get_or_create_config(self, session, config_name: str) -> Optional[Config]:
        """–û—Ç—Ä–∏–º—É—î –∞–±–æ —Å—Ç–≤–æ—Ä—é—î –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é."""
        if not config_name:
            return None
        
        # –í–∏—Ç—è–≥—É—î–º–æ –Ω–∞–∑–≤—É –∫–æ–Ω—Ñ—ñ–≥—É –∑ URL
        if 'fileName=' in config_name:
            # –í–∏—Ç—è–≥—É—î–º–æ –Ω–∞–∑–≤—É —Ñ–∞–π–ª—É –∑ URL
            config_display_name = config_name.split('fileName=')[-1].split('&')[0]
            config_display_name = config_display_name.replace('%2F', '/').replace('%2f', '/')
        else:
            config_display_name = config_name
        
        # –®—É–∫–∞—î–º–æ —ñ—Å–Ω—É—é—á–∏–π –∫–æ–Ω—Ñ—ñ–≥
        config = session.query(Config).filter(Config.name == config_display_name).first()
        if config:
            return config
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π
        config = Config(
            name=config_display_name,
            description=f"Configuration: {config_display_name}",
            url=config_name if config_name.startswith('http') else None
        )
        session.add(config)
        session.flush()
        return config
    
    def close(self):
        """–ó–∞–∫—Ä–∏–≤–∞—î —Ä–µ—Å—É—Ä—Å–∏."""
        if self.qa_repo:
            self.qa_repo.close()


@click.command()
@click.option('--checklist', '-c', help='–ù–∞–∑–≤–∞ —á–µ–∫–ª—ñ—Å—Ç–∞ –∞–±–æ –π–æ–≥–æ ID')
@click.option('--list-checklists', '-l', is_flag=True, help='–ü–æ–∫–∞–∑–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —á–µ–∫–ª—ñ—Å—Ç—ñ–≤')
@click.option('--dry-run', is_flag=True, help='–¢—ñ–ª—å–∫–∏ –∞–Ω–∞–ª—ñ–∑ –±–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –±–∞–∑—É')
def main(checklist, list_checklists, dry_run):
    """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤ –¥–ª—è –±—É–¥—å-—è–∫–æ–≥–æ —á–µ–∫–ª—ñ—Å—Ç–∞."""
    
    if list_checklists:
        asyncio.run(list_available_checklists())
        return
    
    if not checklist:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞: –ü–æ—Ç—Ä—ñ–±–Ω–æ –≤–∫–∞–∑–∞—Ç–∏ --checklist –∞–±–æ --list-checklists")
        print("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ --help –¥–ª—è –¥–æ–≤—ñ–¥–∫–∏")
        return
    
    print("üéØ –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤")
    print("=" * 60)
    
    extractor = UniversalChecklistExtractor()
    
    try:
        if dry_run:
            print("üîç –†–ï–ñ–ò–ú –ê–ù–ê–õ–Ü–ó–£ (–±–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è)")
            
        result = asyncio.run(extractor.extract_and_populate_testcases(checklist))
        
        if result["success"]:
            print("\nüéâ –£–°–ü–Ü–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
            print("=" * 60)
            print(f"‚úÖ –î–æ–¥–∞–Ω–æ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤: {result['testcases_added']}")
            print(f"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ –∫–æ–Ω—Ñ—ñ–≥—ñ–≤: {result['configs_created']}")
            print(f"‚úÖ –ß–µ–∫–ª—ñ—Å—Ç –æ–Ω–æ–≤–ª–µ–Ω–æ: {result['checklist_updated']}")
        else:
            print(f"\n‚ùå –ü–û–ú–ò–õ–ö–ê: {result['error']}")
            
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è –ü–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    finally:
        extractor.close()


async def list_available_checklists():
    """–ü–æ–∫–∞–∑—É—î —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —á–µ–∫–ª—ñ—Å—Ç—ñ–≤."""
    print("üìã –î–æ—Å—Ç—É–ø–Ω—ñ —á–µ–∫–ª—ñ—Å—Ç:")
    print("=" * 60)
    
    qa_repo = QARepository()
    session = qa_repo.get_session()
    
    try:
        checklists = session.query(Checklist).order_by(Checklist.title).all()
        
        for checklist in checklists:
            testcase_count = session.query(TestCase).filter(TestCase.checklist_id == checklist.id).count()
            status = "‚úÖ –ó–∞–ø–æ–≤–Ω–µ–Ω–∏–π" if testcase_count > 0 else "‚ùå –ü–æ—Ä–æ–∂–Ω—ñ–π"
            
            print(f"ID: {checklist.id:3d} | {status} | {checklist.title} ({testcase_count} —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤)")
            
    finally:
        session.close()
        qa_repo.close()


if __name__ == "__main__":
    main()
