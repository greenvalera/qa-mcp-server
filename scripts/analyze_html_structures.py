#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É HTML —Å—Ç—Ä—É–∫—Ç—É—Ä —Ä—ñ–∑–Ω–∏—Ö —á–µ–∫–ª—ñ—Å—Ç—ñ–≤
"""

import os
import sys
import asyncio
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup, Tag
import json

# Add app to Python path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from app.data.qa_repository import QARepository
from app.models.qa_models import Checklist
from scripts.confluence.confluence_real import RealConfluenceAPI


class HTMLStructureAnalyzer:
    """–ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä HTML —Å—Ç—Ä—É–∫—Ç—É—Ä —á–µ–∫–ª—ñ—Å—Ç—ñ–≤"""
    
    def __init__(self):
        self.qa_repo = QARepository()
        self.confluence_api = RealConfluenceAPI()
        self.analysis_results = []
    
    def analyze_checklist_structures(self, checklist_ids: List[int]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ HTML —Ç–∞–±–ª–∏—Ü—å –¥–ª—è —Å–ø–∏—Å–∫—É —á–µ–∫–ª—ñ—Å—Ç—ñ–≤"""
        
        print(f"üîç –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ {len(checklist_ids)} —á–µ–∫–ª—ñ—Å—Ç—ñ–≤...")
        
        for checklist_id in checklist_ids:
            try:
                print(f"\nüìã –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —á–µ–∫–ª—ñ—Å—Ç ID: {checklist_id}")
                result = self._analyze_single_checklist(checklist_id)
                if result:
                    self.analysis_results.append(result)
            except Exception as e:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É —á–µ–∫–ª—ñ—Å—Ç–∞ {checklist_id}: {e}")
        
        return self._generate_summary()
    
    def _analyze_single_checklist(self, checklist_id: int) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª—ñ–∑—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ–¥–Ω–æ–≥–æ —á–µ–∫–ª—ñ—Å—Ç–∞"""
        
        session = self.qa_repo.get_session()
        try:
            checklist = session.query(Checklist).filter(Checklist.id == checklist_id).first()
            if not checklist:
                print(f"‚ùå –ß–µ–∫–ª—ñ—Å—Ç {checklist_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                return None
            
            print(f"   üìÑ {checklist.title}")
            
            # –û—Ç—Ä–∏–º—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç
            page_content = self.confluence_api.get_page_content(checklist.confluence_page_id)
            if not page_content:
                print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç")
                return None
            
            # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            analysis = self._analyze_html_structure(page_content['content'], checklist.title)
            analysis['checklist_id'] = checklist_id
            analysis['checklist_title'] = checklist.title
            
            return analysis
            
        finally:
            session.close()
    
    def _analyze_html_structure(self, html_content: str, title: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª—ñ–∑—É—î HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–Ω—Ç–µ–Ω—Ç—É"""
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        analysis = {
            'title': title,
            'tables_found': 0,
            'table_structures': [],
            'sections_found': [],
            'testcase_patterns': [],
            'html_size': len(html_content),
            'normalized_size': len(self.confluence_api.normalize_content(html_content))
        }
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ —Ç–∞–±–ª–∏—Ü—ñ
        tables = soup.find_all('table')
        analysis['tables_found'] = len(tables)
        
        for i, table in enumerate(tables):
            table_analysis = self._analyze_table_structure(table, i)
            if table_analysis:
                analysis['table_structures'].append(table_analysis)
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Å–µ–∫—Ü—ñ—ó
        analysis['sections_found'] = self._find_sections(soup)
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∏ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤
        analysis['testcase_patterns'] = self._analyze_testcase_patterns(soup)
        
        return analysis
    
    def _analyze_table_structure(self, table: Tag, table_index: int) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª—ñ–∑—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ñ"""
        
        rows = table.find_all('tr')
        if not rows:
            return None
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        header_row = rows[0]
        headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ —Ç–∞–±–ª–∏—Ü—è –∑ —Ç–µ—Å—Ç–∫–µ–π—Å–∞–º–∏
        is_testcase_table = self._is_testcase_table(headers)
        
        table_analysis = {
            'table_index': table_index,
            'rows_count': len(rows),
            'columns_count': len(headers),
            'headers': headers,
            'is_testcase_table': is_testcase_table,
            'sections_in_table': [],
            'testcase_rows': 0,
            'section_headers': []
        }
        
        if is_testcase_table:
            # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ä—è–¥–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Å–µ–∫—Ü—ñ–π —Ç–∞ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤
            for i, row in enumerate(rows[1:], 1):  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                cells = row.find_all(['td', 'th'])
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü—ñ—ó
                if self._is_section_header_row(row, cells):
                    section_name = self._extract_section_name_from_row(cells)
                    table_analysis['sections_in_table'].append(section_name)
                    table_analysis['section_headers'].append({
                        'row_index': i,
                        'section_name': section_name,
                        'colspan': self._get_colspan(cells)
                    })
                else:
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ —Ç–µ—Å—Ç–∫–µ–π—Å
                    if self._is_testcase_row(cells):
                        table_analysis['testcase_rows'] += 1
        
        return table_analysis
    
    def _is_testcase_table(self, headers: List[str]) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î —Ç–∞–±–ª–∏—Ü—è —Ç–∞–±–ª–∏—Ü–µ—é –∑ —Ç–µ—Å—Ç–∫–µ–π—Å–∞–º–∏"""
        
        header_text = ' '.join(headers).upper()
        
        # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ—Å—Ç–∫–µ–π—Å —Ç–∞–±–ª–∏—Ü—å
        testcase_keywords = [
            'STEP', 'EXPECTED', 'PRIORITY', 'CONFIG', 'SCREENSHOT',
            '–®–ê–ì', '–û–ñ–ò–î–ê–ï–ú–´–ô', '–ü–†–ò–û–†–ò–¢–ï–¢', '–ö–û–ù–§–ò–ì', '–°–ö–†–ò–ù–®–û–¢'
        ]
        
        return any(keyword in header_text for keyword in testcase_keywords)
    
    def _is_section_header_row(self, row: Tag, cells: List[Tag]) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î —Ä—è–¥–æ–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Å–µ–∫—Ü—ñ—ó"""
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ colspan
        for cell in cells:
            colspan = cell.get('colspan')
            if colspan and int(colspan) >= 3:  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü—ñ—ó –∑–∞–π–º–∞—î –∫—ñ–ª—å–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
                text = cell.get_text(strip=True).upper()
                if text in ['GENERAL', 'CUSTOM'] or any(keyword in text for keyword in ['SECTION', '–†–ê–ó–î–ï–õ']):
                    return True
        
        return False
    
    def _extract_section_name_from_row(self, cells: List[Tag]) -> str:
        """–í–∏—Ç—è–≥—É—î –Ω–∞–∑–≤—É —Å–µ–∫—Ü—ñ—ó –∑ —Ä—è–¥–∫–∞"""
        
        for cell in cells:
            text = cell.get_text(strip=True).upper()
            if text in ['GENERAL', 'CUSTOM']:
                return text
            elif 'SECTION' in text or '–†–ê–ó–î–ï–õ' in text:
                return text
        
        return 'UNKNOWN'
    
    def _get_colspan(self, cells: List[Tag]) -> int:
        """–û—Ç—Ä–∏–º—É—î –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π colspan –∑ –∫–æ–º—ñ—Ä–æ–∫"""
        
        max_colspan = 0
        for cell in cells:
            colspan = cell.get('colspan')
            if colspan:
                max_colspan = max(max_colspan, int(colspan))
        
        return max_colspan
    
    def _is_testcase_row(self, cells: List[Tag]) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î —Ä—è–¥–æ–∫ —Ç–µ—Å—Ç–∫–µ–π—Å–æ–º"""
        
        if len(cells) < 3:
            return False
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –≤–º—ñ—Å—Ç –≤ –∫–ª—é—á–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
        step_cell = cells[1] if len(cells) > 1 else None
        expected_cell = cells[2] if len(cells) > 2 else None
        
        if step_cell and expected_cell:
            step_text = step_cell.get_text(strip=True)
            expected_text = expected_cell.get_text(strip=True)
            
            # –¢–µ—Å—Ç–∫–µ–π—Å –ø–æ–≤–∏–Ω–µ–Ω –º–∞—Ç–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –≤–º—ñ—Å—Ç—É
            return len(step_text) > 10 and len(expected_text) > 5
        
        return False
    
    def _find_sections(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """–ó–Ω–∞—Ö–æ–¥–∏—Ç—å –≤—Å—ñ —Å–µ–∫—Ü—ñ—ó –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ñ"""
        
        sections = []
        
        # –®—É–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å–µ–∫—Ü—ñ–π
        section_patterns = [
            'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
            'div[class*="section"]',
            'div[class*="header"]'
        ]
        
        for pattern in section_patterns:
            elements = soup.select(pattern)
            for element in elements:
                text = element.get_text(strip=True).upper()
                if any(keyword in text for keyword in ['GENERAL', 'CUSTOM', 'SECTION', '–†–ê–ó–î–ï–õ']):
                    sections.append({
                        'tag': element.name,
                        'text': text,
                        'class': element.get('class', [])
                    })
        
        return sections
    
    def _analyze_testcase_patterns(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª—ñ–∑—É—î –ø–∞—Ç—Ç–µ—Ä–Ω–∏ —Ç–µ—Å—Ç–∫–µ–π—Å—ñ–≤"""
        
        patterns = []
        
        # –®—É–∫–∞—î–º–æ —Ä—è–¥–∫–∏ –∑ –Ω–æ–º–µ—Ä–∞–º–∏ —Ç–∞ –∫—Ä–æ–∫–∞–º–∏
        rows = soup.find_all('tr')
        for row in rows:
            cells = row.find_all(['td', 'th'])
            if len(cells) >= 3:
                first_cell = cells[0].get_text(strip=True)
                second_cell = cells[1].get_text(strip=True)
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ –Ω–æ–º–µ—Ä–æ–≤–∞–Ω–∏–π —Ä—è–¥–æ–∫
                if first_cell.isdigit() and len(second_cell) > 10:
                    patterns.append({
                        'type': 'numbered_testcase',
                        'number': first_cell,
                        'step_preview': second_cell[:50] + '...' if len(second_cell) > 50 else second_cell
                    })
        
        return patterns[:10]  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–µ—Ä—à—ñ 10 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
    
    def _generate_summary(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä—É—î –ø—ñ–¥—Å—É–º–æ–∫ –∞–Ω–∞–ª—ñ–∑—É"""
        
        if not self.analysis_results:
            return {'error': '–ù–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É'}
        
        summary = {
            'total_checklists': len(self.analysis_results),
            'table_statistics': {
                'total_tables': sum(r['tables_found'] for r in self.analysis_results),
                'testcase_tables': sum(len([t for t in r['table_structures'] if t['is_testcase_table']]) for r in self.analysis_results),
                'avg_tables_per_checklist': sum(r['tables_found'] for r in self.analysis_results) / len(self.analysis_results)
            },
            'section_analysis': {
                'unique_sections': set(),
                'section_frequency': {}
            },
            'structure_variations': [],
            'recommendations': []
        }
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Å–µ–∫—Ü—ñ—ó
        for result in self.analysis_results:
            for section in result['sections_found']:
                section_name = section['text']
                summary['section_analysis']['unique_sections'].add(section_name)
                summary['section_analysis']['section_frequency'][section_name] = \
                    summary['section_analysis']['section_frequency'].get(section_name, 0) + 1
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ set –≤ list –¥–ª—è JSON —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
        summary['section_analysis']['unique_sections'] = list(summary['section_analysis']['unique_sections'])
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –≤–∞—Ä—ñ–∞—Ü—ñ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä
        for result in self.analysis_results:
            for table in result['table_structures']:
                if table['is_testcase_table']:
                    structure_variation = {
                        'checklist_title': result['checklist_title'],
                        'columns': table['columns_count'],
                        'headers': table['headers'],
                        'sections': table['sections_in_table'],
                        'testcase_count': table['testcase_rows']
                    }
                    summary['structure_variations'].append(structure_variation)
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        summary['recommendations'] = self._generate_recommendations(summary)
        
        return summary
    
    def _generate_recommendations(self, summary: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä—É—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞–Ω–∞–ª—ñ–∑—É"""
        
        recommendations = []
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –≤–∞—Ä—ñ–∞—Ü—ñ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä
        if summary['structure_variations']:
            column_counts = [v['columns'] for v in summary['structure_variations']]
            unique_columns = set(column_counts)
            
            if len(unique_columns) > 1:
                recommendations.append(f"–í–∏—è–≤–ª–µ–Ω–æ {len(unique_columns)} —Ä—ñ–∑–Ω–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä —Ç–∞–±–ª–∏—Ü—å –∑ –∫—ñ–ª—å–∫—ñ—Å—Ç—é –∫–æ–ª–æ–Ω–æ–∫: {sorted(unique_columns)}")
            
            # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            all_headers = []
            for variation in summary['structure_variations']:
                all_headers.extend(variation['headers'])
            
            unique_headers = set(all_headers)
            if len(unique_headers) > 10:
                recommendations.append(f"–í–∏—è–≤–ª–µ–Ω–æ {len(unique_headers)} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ –∫–æ–ª–æ–Ω–æ–∫ - –ø–æ—Ç—Ä—ñ–±–Ω–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è")
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Å–µ–∫—Ü—ñ—ó
        sections = summary['section_analysis']['unique_sections']
        if len(sections) > 2:
            recommendations.append(f"–í–∏—è–≤–ª–µ–Ω–æ {len(sections)} —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ —Å–µ–∫—Ü—ñ–π: {list(sections)}")
        
        return recommendations
    
    def close(self):
        """–ó–∞–∫—Ä–∏–≤–∞—î —Ä–µ—Å—É—Ä—Å–∏"""
        if self.qa_repo:
            self.qa_repo.close()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    
    # –°–ø–∏—Å–æ–∫ —á–µ–∫–ª—ñ—Å—Ç—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    checklist_ids = [286, 287, 288, 289, 290, 291, 292, 293, 294, 295]
    
    analyzer = HTMLStructureAnalyzer()
    
    try:
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
        summary = analyzer.analyze_checklist_structures(checklist_ids)
        
        # –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        print("\n" + "="*80)
        print("üìä –ü–Ü–î–°–£–ú–û–ö –ê–ù–ê–õ–Ü–ó–£ HTML –°–¢–†–£–ö–¢–£–†")
        print("="*80)
        
        print(f"\nüìã –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   - –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —á–µ–∫–ª—ñ—Å—Ç—ñ–≤: {summary['total_checklists']}")
        print(f"   - –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü—å: {summary['table_statistics']['total_tables']}")
        print(f"   - –¢–∞–±–ª–∏—Ü—å –∑ —Ç–µ—Å—Ç–∫–µ–π—Å–∞–º–∏: {summary['table_statistics']['testcase_tables']}")
        print(f"   - –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–∞–±–ª–∏—Ü—å –Ω–∞ —á–µ–∫–ª—ñ—Å—Ç: {summary['table_statistics']['avg_tables_per_checklist']:.1f}")
        
        print(f"\nüè∑Ô∏è –ê–Ω–∞–ª—ñ–∑ —Å–µ–∫—Ü—ñ–π:")
        print(f"   - –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å–µ–∫—Ü—ñ–π: {len(summary['section_analysis']['unique_sections'])}")
        for section, count in summary['section_analysis']['section_frequency'].items():
            print(f"     ‚Ä¢ {section}: {count} —Ä–∞–∑—ñ–≤")
        
        print(f"\nüîß –í–∞—Ä—ñ–∞—Ü—ñ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä:")
        for i, variation in enumerate(summary['structure_variations'][:5], 1):
            print(f"   {i}. {variation['checklist_title']}")
            print(f"      - –ö–æ–ª–æ–Ω–æ–∫: {variation['columns']}")
            print(f"      - –°–µ–∫—Ü—ñ–π: {variation['sections']}")
            print(f"      - –¢–µ—Å—Ç–∫–µ–π—Å—ñ–≤: {variation['testcase_count']}")
        
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:")
        for i, rec in enumerate(summary['recommendations'], 1):
            print(f"   {i}. {rec}")
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
        with open('/home/vpogorelov/projects/qa_mcp/html_structure_analysis.json', 'w', encoding='utf-8') as f:
            json.dump({
                'summary': summary,
                'detailed_results': analyzer.analysis_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ html_structure_analysis.json")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    finally:
        analyzer.close()


if __name__ == "__main__":
    main()
